{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression simulation with 10 permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbenja13/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n"
     ]
    }
   ],
   "source": [
    "import os,errno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from plotnine import *\n",
    "from scripts import raffe\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_regression\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score as evar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(p, fn, width=7, height=7):\n",
    "    '''Save plot as svg, png, and pdf with specific label and dimension.'''\n",
    "    for ext in ['.svg', '.png', '.pdf']:\n",
    "        p.save(fn+ext, width=width, height=height)\n",
    "        \n",
    "\n",
    "def mkdir_p(directory):\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "\n",
    "def generate_regression_data(seed=13):\n",
    "    # Create a dataset with only 10 informative features\n",
    "    X, y = make_regression(\n",
    "        n_samples=500, n_features=1000, n_informative=10, bias=0.1,\n",
    "        n_targets=1, noise=10, random_state=seed\n",
    "    )\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    regr = RandomForestRegressor(n_estimators=100, oob_score=True, \n",
    "                                 n_jobs=-1, random_state=seed)\n",
    "    return X, y, cv, regr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfecv_run(X, y, cv, regr, outdir, seed, step=100):\n",
    "    # Instantiate RFECV visualizer with a random forest regression\n",
    "    start = time()\n",
    "    visualizer = RFECV(regr, cv=cv, step=step, n_jobs=-1)\n",
    "    visualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "    visualizer.show(outpath=\"%s/rfecv_regression.png\" % outdir)\n",
    "    visualizer.show(outpath=\"%s/rfecv_regression.pdf\" % outdir)\n",
    "    visualizer.show()           # Finalize and render the figure\n",
    "    end = time()\n",
    "    print(f\"Runtime of the program is {end - start}\")\n",
    "    fold_dict = {0:'Fold_1', 1:'Fold_2', 2:'Fold_3', 3:'Fold_4', 4:'Fold_5'}\n",
    "    rfe_df = pd.DataFrame(visualizer.cv_scores_).rename(columns=fold_dict)\n",
    "    rfe_df['n_features'] = visualizer.n_feature_subsets_\n",
    "    rfe_df['seed'] = seed\n",
    "    rfe_df['best_n'] = visualizer.n_features_\n",
    "    rfe_df['cpu_total'] = end - start\n",
    "    return rfe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_raffe_regr(estimator, x_train, x_test, y_train, y_test, fold, outdir):\n",
    "    features = [\"feature_%d\" % x for x in range(x_train.shape[1])]\n",
    "    d, pfirst = raffe.feature_elimination(estimator, x_train, y_train, \n",
    "                                          np.array(features), \n",
    "                                          fold, outdir, \n",
    "                                          elimination_rate=0.1, \n",
    "                                          RANK=True)\n",
    "    df_elim = pd.DataFrame([{'fold':fold,\n",
    "                             'n features':k,\n",
    "                             'R2':d[k][1], \n",
    "                             'Mean Square Error':d[k][2], \n",
    "                             'Explained Variance':d[k][3]} for k in d.keys()])\n",
    "    n_features_max = max(d, key=lambda x: d[x][1])\n",
    "    try:\n",
    "        n_features,_ = raffe.extract_max_lowess(d)\n",
    "    except ValueError:\n",
    "        n_features = n_features_max \n",
    "    estimator.fit(x_train[:,d[n_features][4]], y_train)\n",
    "    labels_pred = estimator.predict(x_test[:, d[n_features][4]])\n",
    "    metrics_df = pd.DataFrame({'n_features_max': n_features_max, \n",
    "                               'n_features': n_features, \n",
    "                               'train_r2':raffe.oob_score_r2(estimator, y_train), \n",
    "                               'train_evar':raffe.oob_score_evar(estimator, y_train),\n",
    "                               'train_mse':raffe.oob_score_mse(estimator, y_train), \n",
    "                               'test_r2':r2_score(y_test, labels_pred), \n",
    "                               'test_evar':evar(y_test, labels_pred,\n",
    "                                                multioutput='uniform_average'), \n",
    "                               'test_mse':mean_squared_error(y_test, labels_pred)}, \n",
    "                              index=[fold])\n",
    "    return df_elim, metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raffe_plot(df_dict, outdir, li):\n",
    "    dft = pd.melt(df_dict, id_vars=['fold', 'n features'], \n",
    "                  value_vars=['R2', 'Mean Square Error', \n",
    "                              'Explained Variance'],\n",
    "                  var_name='Metrics', value_name='Score')\n",
    "    gg = ggplot(dft, aes(x='n features', y='Score', color='Metrics')) +\\\n",
    "        geom_jitter(size=1, alpha=0.6) + facet_wrap('~Metrics', scales='free') +\\\n",
    "        geom_vline(xintercept=li, color='black', linetype='dashed') +\\\n",
    "        scale_x_log10() + theme_classic() + theme(legend_position=\"top\")\n",
    "    save_plot(gg, '%s/raffe_feature_selection' % outdir, 12, 4)\n",
    "    return gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raffe_run(X, y, cv, cla, outdir, seed):\n",
    "    start = time()\n",
    "    df_dict = pd.DataFrame()\n",
    "    output = pd.DataFrame()\n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_elim, metrics_df = run_raffe_regr(regr, X_train, X_test, \n",
    "                                             y_train, y_test, fold, \n",
    "                                             outdir)\n",
    "        df_dict = pd.concat([df_dict, df_elim], axis=0)\n",
    "        output = pd.concat([output, metrics_df.reset_index()], axis=0)\n",
    "        fold += 1\n",
    "    end = time()\n",
    "    output['seed'] = seed\n",
    "    output['cpu_total'] = end - start\n",
    "    li = output.set_index('index').loc[:, 'n_features'].mean()\n",
    "    gg = raffe_plot(df_dict, outdir, li)\n",
    "    print(gg)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directory\n",
    "directory = 'regression_simu/'\n",
    "mkdir_p(directory)\n",
    "\n",
    "for seed in range(1, 11):\n",
    "    X, y, cv, regr = generate_regression_data(seed)\n",
    "    outdir = '%s/permutation_%d' % (directory, seed)\n",
    "    mkdir_p(outdir)\n",
    "    ## RFE\n",
    "    rfe = rfecv_run(X, y, cv, regr, outdir, seed, step=100)\n",
    "    rfe.to_csv('%s/rfecv_results_%d_step.txt' % (directory, 100),\n",
    "               sep='\\t', mode='a', index=True,\n",
    "               header=True if seed == 1 else False)\n",
    "    rfe = rfecv_run(X, y, cv, regr, outdir, seed, step=10)\n",
    "    rfe.to_csv('%s/rfecv_results_%d_step.txt' % (directory, 10),\n",
    "               sep='\\t', mode='a', index=True,\n",
    "               header=True if seed == 1 else False)\n",
    "    ## RaFFE\n",
    "    o = raffe_run(X, y, cv, regr, outdir, seed)\n",
    "    o.to_csv('%s/raffe_results.txt' % (directory),\n",
    "             sep='\\t', mode='a', index=True,\n",
    "             header=True if seed == 1 else False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
