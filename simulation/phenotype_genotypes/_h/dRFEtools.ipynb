{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dRFEtools simulations with phenotype ~ genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,errno\n",
    "import functools\n",
    "import dRFEtools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score as evar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_y_var():\n",
    "    # Correlated component\n",
    "    Ycorr = pd.read_csv(\"../../_m/genotype_simulation/Y_correlatedBg_genotype_simulation.csv\", index_col=0)\n",
    "    # Genetic component\n",
    "    YgenBg = pd.read_csv(\"../../_m/genotype_simulation/Y_genBg_genotype_simulation.csv\", index_col=0)\n",
    "    YgenFixed = pd.read_csv(\"../../_m/genotype_simulation/Y_genFixed_genotype_simulation.csv\", index_col=0)\n",
    "    # Noise component\n",
    "    YnoiseBg = pd.read_csv(\"../../_m/genotype_simulation/Y_noiseBg_genotype_simulation.csv\", index_col=0)\n",
    "    YnoiseFixed = pd.read_csv(\"../../_m/genotype_simulation/Y_noiseFixed_genotype_simulation.csv\", index_col=0)\n",
    "    # Combine\n",
    "    Y = Ycorr + YgenBg + YgenFixed + YnoiseBg + YnoiseFixed\n",
    "    return Y\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_X_var():\n",
    "    snp_df = pd.read_csv(\"../../_m/genotype_simulation/Genotypes_genotype_simulation.csv\", \n",
    "                         index_col=0).T\n",
    "    r = pd.get_dummies(snp_df, columns=snp_df.columns, dummy_na=True)\n",
    "    r.columns = r.columns.str.replace('\\.\\d+', '', regex=True)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(directory):\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "            \n",
    "def load_data(simu):\n",
    "    X = get_X_var()\n",
    "    Y = get_y_var().iloc[:, simu]\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "def run_regr_oob(estimator, x_train, x_test, y_train, y_test, fold, outdir, \n",
    "                 frac, step, simu):\n",
    "    features = x_train.columns\n",
    "    d, pfirst = dRFEtools.rf_rfe(estimator, x_train.values, y_train.values, features, \n",
    "                                fold, outdir, elimination_rate=0.1, RANK=True)\n",
    "    df_elim = pd.DataFrame([{'fold':fold, \"simulation\": simu,\n",
    "                             'n features':k, 'R2 Score':d[k][1], \n",
    "                             'Mean Square Error':d[k][2], \n",
    "                             'Explained Variance':d[k][3]} for k in d.keys()])\n",
    "    n_features_max = max(d, key=lambda x: d[x][1])\n",
    "    try:\n",
    "        ## Max features from lowess curve\n",
    "        n_features, _ = dRFEtools.extract_max_lowess(d, frac=frac, multi=False)\n",
    "        n_redundant, _ = dRFEtools.extract_redundant_lowess(d, frac=frac, \n",
    "                                                            step_size=step, \n",
    "                                                            multi=False)\n",
    "        dRFEtools.plot_with_lowess_vline(d, fold, outdir, frac=frac, \n",
    "                                         step_size=step, classify=False)\n",
    "    except ValueError:\n",
    "        ## For errors in lowess estimate\n",
    "        n_features = n_features_max \n",
    "        n_redundant = n_features\n",
    "    ## Fit model\n",
    "    estimator.fit(x_train, y_train)\n",
    "    all_fts = estimator.predict(x_test)\n",
    "    estimator.fit(x_train.values[:, d[n_redundant][4]], y_train)\n",
    "    labels_pred_redundant = estimator.predict(x_test.values[:, d[n_redundant][4]])\n",
    "    estimator.fit(x_train.values[:,d[n_features][4]], y_train)\n",
    "    labels_pred = estimator.predict(x_test.values[:, d[n_features][4]])\n",
    "    ## Output test predictions\n",
    "    pd.DataFrame({'fold': fold, \"simulation\": simu, 'real': y_test, \n",
    "                  'predict_all': all_fts, 'predict_max': labels_pred, \n",
    "                  'predict_redundant': labels_pred_redundant})\\\n",
    "      .to_csv(\"%s/test_predictions.txt\" % outdir, sep='\\t', mode='a', index=True, \n",
    "              header=True if fold == 0 else False)\n",
    "    output = dict()\n",
    "    output['simulation'] = simu\n",
    "    output['n_features'] = n_features\n",
    "    output['n_redundant'] = n_redundant\n",
    "    output['n_max'] = n_features_max\n",
    "    output['train_r2'] = dRFEtools.oob_score_r2(estimator, y_train)\n",
    "    output['train_mse'] = dRFEtools.oob_score_mse(estimator, y_train)\n",
    "    output['train_evar'] = dRFEtools.oob_score_evar(estimator, y_train)\n",
    "    output['test_r2'] = r2_score(y_test, labels_pred)\n",
    "    output['test_mse'] = mean_squared_error(y_test, labels_pred)\n",
    "    output['test_evar'] = evar(y_test, labels_pred, multioutput='uniform_average')\n",
    "    metrics_df = pd.DataFrame.from_records(output, index=[simu]).reset_index().drop('index', axis=1)\n",
    "    return df_elim, metrics_df\n",
    "\n",
    "\n",
    "def run_regr_dev(estimator, x_train, x_test, y_train, y_test, fold, outdir, \n",
    "                 frac, step, simu):\n",
    "    features = x_train.columns\n",
    "    d, pfirst = dRFEtools.dev_rfe(estimator, x_train.values, y_train.values, features, \n",
    "                                 fold, outdir, elimination_rate=0.1, RANK=True)\n",
    "    df_elim = pd.DataFrame([{'fold':fold, \"simulation\": simu,\n",
    "                             'n features':k, 'R2 Score':d[k][1], \n",
    "                             'Mean Square Error':d[k][2], \n",
    "                             'Explained Variance':d[k][3]} for k in d.keys()])\n",
    "    n_features_max = max(d, key=lambda x: d[x][1])\n",
    "    try:\n",
    "        ## Max features from lowess curve\n",
    "        ### multiple classification is False by default\n",
    "        n_features, _ = dRFEtools.extract_max_lowess(d, frac=frac)\n",
    "        n_redundant, _ = dRFEtools.extract_redundant_lowess(d, frac=frac, \n",
    "                                                            step_size=step)\n",
    "        dRFEtools.plot_with_lowess_vline(d, fold, outdir, frac=frac, \n",
    "                                         step_size=step, classify=False)\n",
    "    except ValueError:\n",
    "        ## For errors in lowess estimate\n",
    "        n_features = n_features_max \n",
    "        n_redundant = n_features\n",
    "    ## Fit model\n",
    "    x_dev, x_test, y_dev, y_test = train_test_split(x_train, y_train)\n",
    "    estimator.fit(x_train, y_train)\n",
    "    all_fts = estimator.predict(x_test)\n",
    "    estimator.fit(x_train.values[:, d[n_redundant][4]], y_train)\n",
    "    labels_pred_redundant = estimator.predict(x_test.values[:, d[n_redundant][4]])\n",
    "    estimator.fit(x_train.values[:,d[n_features][4]], y_train)\n",
    "    labels_pred = estimator.predict(x_test.values[:, d[n_features][4]])\n",
    "    ## Output test predictions\n",
    "    pd.DataFrame({'fold': fold, \"simulation\": simu, 'real': y_test, \n",
    "                  'predict_all': all_fts, 'predict_max': labels_pred, \n",
    "                  'predict_redundant': labels_pred_redundant})\\\n",
    "      .to_csv(\"%s/test_predictions.txt\" % outdir, sep='\\t', mode='a', index=True, \n",
    "              header=True if fold == 0 else False)\n",
    "    output = dict()\n",
    "    output['simulation'] = simu\n",
    "    output['fold'] = fold\n",
    "    output['n_features'] = n_features\n",
    "    output['n_redundant'] = n_redundant\n",
    "    output['n_max'] = n_features_max\n",
    "    output['train_r2'] = dRFEtools.dev_score_r2(estimator, x_dev.values[:,d[n_features][4]], y_dev)\n",
    "    output['train_mse'] = dRFEtools.dev_score_mse(estimator, x_dev.values[:,d[n_features][4]], y_dev)\n",
    "    output['train_evar'] = dRFEtools.dev_score_evar(estimator, x_dev.values[:,d[n_features][4]], y_dev)\n",
    "    output['test_r2'] = r2_score(y_test, labels_pred)\n",
    "    output['test_mse'] = mean_squared_error(y_test, labels_pred)\n",
    "    output['test_evar'] = evar(y_test, labels_pred, multioutput='uniform_average')\n",
    "    metrics_df = pd.DataFrame.from_records(output, index=[simu]).reset_index().drop('index', axis=1)\n",
    "    return df_elim, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'ridge/'\n",
    "mkdir_p(outdir)\n",
    "regr = dRFEtools.Ridge(random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(0)\n",
    "fold = 1\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    fold += 1\n",
    "fold -= 1\n",
    "\n",
    "features = X_train.columns\n",
    "d, pfirst = dRFEtools.dev_rfe(regr, X_train.values, y_train.values, features, \n",
    "                             fold, outdir, elimination_rate=0.1, RANK=False)\n",
    "\n",
    "for frac in [0.2, 0.25, 0.3, 0.35]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=frac, step_size=0.05, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_size in [0.01, 0.02, 0.03, 0.04]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=0.3, step_size=step_size, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_lt = []; simu_lt = []\n",
    "for simu in range(15):\n",
    "    X, y = load_data(simu)\n",
    "    simu_out = \"%s/simulate_%d\" % (outdir, simu)\n",
    "    mkdir_p(simu_out)\n",
    "    frac = 0.3; step=0.04; fold = 0\n",
    "    df_dict = pd.DataFrame()\n",
    "    output = pd.DataFrame()\n",
    "    start = time()\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_elim, metrics_df = run_regr_dev(regr, X_train, X_test, \n",
    "                                           y_train, y_test, fold, \n",
    "                                           simu_out, frac, step, simu)\n",
    "        df_dict = pd.concat([df_dict, df_elim], axis=0)\n",
    "        output = pd.concat([output, metrics_df], axis=0)\n",
    "        fold += 1\n",
    "    end = time()\n",
    "    df_dict.to_csv(\"%s/dRFE_simulation_elimination.txt\" % outdir,\n",
    "                   sep='\\t', mode='a', index=False, \n",
    "                   header=True if simu == 0 else False)\n",
    "    output.to_csv(\"%s/dRFE_simulation_metrics.txt\" % outdir,\n",
    "                  sep='\\t', mode='a', index=False, \n",
    "                  header=True if simu == 0 else False)\n",
    "    cpu_lt.append(end - start)\n",
    "    simu_lt.append(simu)\n",
    "pd.DataFrame({\"Simulation\": simu_lt, \"CPU Time\": cpu_lt})\\\n",
    "  .to_csv(\"%s/simulation_time.csv\" % outdir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'enet/'\n",
    "mkdir_p(outdir)\n",
    "regr = dRFEtools.ElasticNet(alpha=0.01, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(0)\n",
    "fold = 1\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    fold += 1\n",
    "fold -= 1\n",
    "\n",
    "features = X_train.columns\n",
    "d, pfirst = dRFEtools.dev_rfe(regr, X_train.values, y_train.values, features, \n",
    "                             fold, outdir, elimination_rate=0.1, RANK=False)\n",
    "\n",
    "for frac in [0.2, 0.25, 0.3, 0.35]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=frac, step_size=0.05, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_size in [0.01, 0.02, 0.03, 0.04]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=0.3, step_size=step_size, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_lt = []; simu_lt = []\n",
    "for simu in range(15):\n",
    "    X, y = load_data(simu)\n",
    "    simu_out = \"%s/simulate_%d\" % (outdir, simu)\n",
    "    mkdir_p(simu_out)\n",
    "    frac = 0.3; step=0.01; fold = 0\n",
    "    df_dict = pd.DataFrame()\n",
    "    output = pd.DataFrame()\n",
    "    start = time()\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_elim, metrics_df = run_regr_dev(regr, X_train, X_test, \n",
    "                                           y_train, y_test, fold, \n",
    "                                           simu_out, frac, step, simu)\n",
    "        df_dict = pd.concat([df_dict, df_elim], axis=0)\n",
    "        output = pd.concat([output, metrics_df], axis=0)\n",
    "        fold += 1\n",
    "    end = time()\n",
    "    df_dict.to_csv(\"%s/dRFE_simulation_elimination.txt\" % outdir,\n",
    "                   sep='\\t', mode='a', index=False, \n",
    "                   header=True if simu == 0 else False)\n",
    "    output.to_csv(\"%s/dRFE_simulation_metrics.txt\" % outdir,\n",
    "                  sep='\\t', mode='a', index=False, \n",
    "                  header=True if simu == 0 else False)\n",
    "    cpu_lt.append(end - start)\n",
    "    simu_lt.append(simu)\n",
    "pd.DataFrame({\"Simulation\": simu_lt, \"CPU Time\": cpu_lt})\\\n",
    "  .to_csv(\"%s/simulation_time.csv\" % outdir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'svr/'\n",
    "mkdir_p(outdir)\n",
    "regr = dRFEtools.LinearSVR(random_state=13, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(0)\n",
    "fold = 1\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    fold += 1\n",
    "fold -= 1\n",
    "\n",
    "features = X_train.columns\n",
    "d, pfirst = dRFEtools.dev_rfe(regr, X_train.values, y_train.values, features, \n",
    "                             fold, outdir, elimination_rate=0.1, RANK=False)\n",
    "\n",
    "for frac in [0.2, 0.25, 0.3, 0.35]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=frac, step_size=0.05, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_size in [0.01, 0.02, 0.03, 0.04]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=0.25, step_size=step_size, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_lt = []; simu_lt = []\n",
    "for simu in range(15):\n",
    "    simu_out = \"%s/simulate_%d\" % (outdir, simu)\n",
    "    mkdir_p(simu_out)\n",
    "    X, y = load_data(simu)\n",
    "    frac = 0.20; step=0.03; fold = 0\n",
    "    df_dict = pd.DataFrame()\n",
    "    output = pd.DataFrame()\n",
    "    start = time()\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_elim, metrics_df = run_regr_dev(regr, X_train, X_test, \n",
    "                                           y_train, y_test, fold, \n",
    "                                           simu_out, frac, step, simu)\n",
    "        df_dict = pd.concat([df_dict, df_elim], axis=0)\n",
    "        output = pd.concat([output, metrics_df], axis=0)\n",
    "        fold += 1\n",
    "    end = time()\n",
    "    df_dict.to_csv(\"%s/dRFE_simulation_elimination.txt\" % outdir,\n",
    "                   sep='\\t', mode='a', index=False, \n",
    "                   header=True if simu == 0 else False)\n",
    "    output.to_csv(\"%s/dRFE_simulation_metrics.txt\" % outdir,\n",
    "                  sep='\\t', mode='a', index=False, \n",
    "                  header=True if simu == 0 else False)\n",
    "    cpu_lt.append(end - start)\n",
    "    simu_lt.append(simu)\n",
    "pd.DataFrame({\"Simulation\": simu_lt, \"CPU Time\": cpu_lt})\\\n",
    "  .to_csv(\"%s/simulation_time.csv\" % outdir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'rf/'\n",
    "mkdir_p(outdir)\n",
    "regr = dRFEtools.RandomForestRegressor(n_estimators=100, oob_score=True, \n",
    "                                       n_jobs=-1, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(0)\n",
    "fold = 1\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    fold += 1\n",
    "fold -= 1\n",
    "\n",
    "features = X_train.columns\n",
    "d, pfirst = dRFEtools.rf_rfe(regr, X_train.values, y_train.values, features, \n",
    "                            fold, outdir, elimination_rate=0.2, RANK=False)\n",
    "\n",
    "for frac in [0.2, 0.25, 0.3, 0.35]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=frac, step_size=0.05, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_size in [0.01, 0.02, 0.03, 0.04]:\n",
    "    dRFEtools.optimize_lowess_plot(d, fold, outdir, frac=0.3, step_size=step_size, \n",
    "                                   classify=False, save_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_lt = []; simu_lt = []\n",
    "for simu in range(15):\n",
    "    X, y = load_data(simu)\n",
    "    simu_out = \"%s/simulate_%d\" % (outdir, simu)\n",
    "    mkdir_p(simu_out)\n",
    "    frac = 0.3; step=0.04; fold = 0\n",
    "    df_dict = pd.DataFrame()\n",
    "    output = pd.DataFrame()\n",
    "    start = time()\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_elim, metrics_df = run_regr_oob(regr, X_train, X_test, \n",
    "                                           y_train, y_test, fold, \n",
    "                                           simu_out, frac, step, simu)\n",
    "        df_dict = pd.concat([df_dict, df_elim], axis=0)\n",
    "        output = pd.concat([output, metrics_df], axis=0)\n",
    "        fold += 1\n",
    "    end = time()\n",
    "    df_dict.to_csv(\"%s/dRFE_simulation_elimination.txt\" % outdir,\n",
    "                   sep='\\t', mode='a', index=False, \n",
    "                   header=True if simu == 0 else False)\n",
    "    output.to_csv(\"%s/dRFE_simulation_metrics.txt\" % outdir,\n",
    "                  sep='\\t', mode='a', index=False, \n",
    "                  header=True if simu == 0 else False)\n",
    "    cpu_lt.append(end - start)\n",
    "    simu_lt.append(simu)\n",
    "pd.DataFrame({\"Simulation\": simu_lt, \"CPU Time\": cpu_lt})\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
